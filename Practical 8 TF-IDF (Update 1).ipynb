{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34a1c269",
   "metadata": {},
   "source": [
    "# Practical 8 TF-IDF (Update 1: 22/8/2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2590ce",
   "metadata": {},
   "source": [
    "## Why TF-IDF\n",
    "\n",
    "TF-IDF allows us to score the importance of words in a document, based on how frequently they appear on multiple documents.\n",
    "\n",
    "- If the word appears frequently in a document - assign a high score to that word (term frequency - TF)\n",
    "\n",
    "- If the word appears in a lot of documents - assign a low score to that word. (inverse document frequency - IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8431dc3a",
   "metadata": {},
   "source": [
    "<img src=\"http://www.sefidian.com/wp-content/ql-cache/quicklatex.com-f33b8ece29548d38cf0d06e877c46dd5_l3.svg\" alt=\"1cd646-b0646eda5097486f9cdbf3080798669d-mv2\" border=\"0\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8279779",
   "metadata": {},
   "source": [
    "<img src=\"http://www.sefidian.com/wp-content/ql-cache/quicklatex.com-e06efbe37aaf1d31c1bf0ee44d774b9a_l3.svg\" alt=\"1cd646-b0646eda5097486f9cdbf3080798669d-mv2\" border=\"0\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661f4739",
   "metadata": {},
   "source": [
    "The TF-IDF of a term is calculated by multiplying TF and IDF scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba082e1",
   "metadata": {},
   "source": [
    "<img src=\"http://www.sefidian.com/wp-content/ql-cache/quicklatex.com-4c290738055303eedfd97f880db7f7d8_l3.svg\" alt=\"1cd646-b0646eda5097486f9cdbf3080798669d-mv2\" border=\"0\">\n",
    "\n",
    "Translated into plain English, the importance of a term is high when it occurs a lot in a given document and rarely in others. In short, commonality within a document measured by TF is balanced by rarity between documents measured by IDF.\n",
    "\n",
    "The resulting TF-IDF score reflects the importance of a term for a document in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a76ac0",
   "metadata": {},
   "source": [
    "<img src=\"https://img.picturequotes.com/2/2/1874/less-is-only-more-where-more-is-no-good-quote-1.jpg\" alt=\"1cd646-b0646eda5097486f9cdbf3080798669d-mv2\" border=\"0\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c4dbe5",
   "metadata": {},
   "source": [
    "Let's start to implement TF-IDF!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8149e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955f100b",
   "metadata": {},
   "source": [
    "First, let‚Äôs construct a small corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ad17f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['data science is one of the most important fields of science', # Doc 1\n",
    "          'this is one of the best data science courses',                # Doc 2\n",
    "          'RDS produces data scientist who can analyse data' ]           # Doc 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1139f638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug It!: We can enhance this TF-IDF by REMOVING stopwords from the corpus\n",
    "# However, this section of code comes with some bugs.\n",
    "# Let's try to fix it! (Tips: There are 3 bugs here...üòÅ)\n",
    "\n",
    "tokenized_corpus = [doc.split() for doc in corpus]\n",
    "stop_words = set(stopwords.words('ENG'))\n",
    "# Remove stopwords from each document\n",
    "filtered_corpus = []\n",
    "for doc_tokens in tokenized_corpus:\n",
    "    filtered_tokens = [token for token in doc_tokens if token.lower() in stop_words]\n",
    "    filtered_corpus.appends(' '.join(filtered_tokens))\n",
    "    \n",
    "print(filtered_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f877d0f",
   "metadata": {},
   "source": [
    "Next, we‚Äôll create a word set for the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf38e05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words_set = set()\n",
    " \n",
    "for doc in  corpus:\n",
    "    words = doc.split(' ')\n",
    "    words_set = words_set.union(set(words))\n",
    "     \n",
    "print('Number of words in the corpus:',len(words_set)) #You should able to tell how many 'dimensions' is available for this set of docs\n",
    "print('The words in the corpus: \\n', words_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e45ed3a",
   "metadata": {},
   "source": [
    "# Computing Term Frequency\n",
    "\n",
    "Now we can create a dataframe by the number of documents in the corpus and the word set, and use that information to compute the term frequency (TF):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1199e658",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_docs = len(corpus)         #¬∑Number of documents in the corpus\n",
    "n_words_set = len(words_set) #¬∑Number of unique words in the\n",
    " \n",
    "df_tf = pd.DataFrame(np.zeros((n_docs, n_words_set)), columns=words_set)\n",
    " \n",
    "# Compute Term Frequency (TF)\n",
    "for i in range(n_docs):\n",
    "    words = corpus[i].split(' ') # Words in the document\n",
    "    for w in words:\n",
    "        df_tf[w][i] = df_tf[w][i] + (1 / len(words))\n",
    "         \n",
    "df_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70df0f7d",
   "metadata": {},
   "source": [
    "# Computing Inverse Document Frequency\n",
    "\n",
    "Now, we‚Äôll compute the inverse document frequency (IDF):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8abad5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"IDF of: \")\n",
    " \n",
    "idf = {}\n",
    " \n",
    "for w in words_set:\n",
    "    k = 0    # number of documents in the corpus that contain this word\n",
    "     \n",
    "    for i in range(n_docs):\n",
    "        if w in corpus[i].split():\n",
    "            k += 1\n",
    "             \n",
    "    idf[w] =  np.log10(n_docs / k)\n",
    "     \n",
    "    print(f'{w:>15}: {idf[w]:>10}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff9a2f1",
   "metadata": {},
   "source": [
    "# Putting it Together: Computing TF-IDF\n",
    "\n",
    "Since we have TF and IDF now, we can compute TF-IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe41746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tf_idf = df_tf.copy()\n",
    " \n",
    "for w in words_set:\n",
    "    for i in range(n_docs):\n",
    "        df_tf_idf[w][i] = df_tf[w][i] * idf[w]\n",
    "         \n",
    "df_tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fc5121",
   "metadata": {},
   "source": [
    "Notice that ‚Äúdata‚Äù has an IDF of 0 because it appears in every document. As a result, ‚Äúis‚Äù is not considered to be an important term in this corpus. This will change slightly in the following sklearn implementation, where ‚Äúdata‚Äù will be non-zero."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
